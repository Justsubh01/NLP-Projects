{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install contractions","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:19.152448Z","iopub.execute_input":"2021-07-20T07:51:19.152831Z","iopub.status.idle":"2021-07-20T07:51:30.835313Z","shell.execute_reply.started":"2021-07-20T07:51:19.152792Z","shell.execute_reply":"2021-07-20T07:51:30.834408Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\nCollecting textsearch>=0.0.21\n  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\nCollecting pyahocorasick\n  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n\u001b[K     |████████████████████████████████| 321 kB 1.2 MB/s eta 0:00:01\n\u001b[?25hCollecting anyascii\n  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n\u001b[K     |████████████████████████████████| 283 kB 8.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n  Building wheel for pyahocorasick (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=102915 sha256=604e1655e23d97ff3c6a0ed6e1f5e12d1e177873fb6fb5a01d02efab700a5f8b\n  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\nSuccessfully built pyahocorasick\nInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install unidecode","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:30.838721Z","iopub.execute_input":"2021-07-20T07:51:30.838997Z","iopub.status.idle":"2021-07-20T07:51:37.300439Z","shell.execute_reply.started":"2021-07-20T07:51:30.838968Z","shell.execute_reply":"2021-07-20T07:51:37.299432Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (1.2.0)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"debug = True","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.305377Z","iopub.execute_input":"2021-07-20T07:51:37.307327Z","iopub.status.idle":"2021-07-20T07:51:37.313362Z","shell.execute_reply.started":"2021-07-20T07:51:37.307284Z","shell.execute_reply":"2021-07-20T07:51:37.312239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport zipfile\nimport string\nimport re\nimport time\nimport sys\nimport random\nimport multiprocessing\nimport more_itertools\n\n\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.318085Z","iopub.execute_input":"2021-07-20T07:51:37.319698Z","iopub.status.idle":"2021-07-20T07:51:37.783310Z","shell.execute_reply.started":"2021-07-20T07:51:37.319662Z","shell.execute_reply":"2021-07-20T07:51:37.782494Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sys.setrecursionlimit(10**8)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.784632Z","iopub.execute_input":"2021-07-20T07:51:37.784995Z","iopub.status.idle":"2021-07-20T07:51:37.789896Z","shell.execute_reply.started":"2021-07-20T07:51:37.784958Z","shell.execute_reply":"2021-07-20T07:51:37.788642Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset,Sampler\nfrom tqdm.notebook import tqdm_notebook\nimport matplotlib.pyplot as plt \n\nfrom sklearn.metrics import f1_score\n\nimport transformers\nfrom transformers import AutoConfig\nfrom transformers import (\n    get_cosine_schedule_with_warmup, \n    get_cosine_with_hard_restarts_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\nfrom IPython.display import clear_output\nfrom tqdm import tqdm, trange\n\n\nimport random\nimport unidecode\nimport contractions\nfrom sklearn.metrics import multilabel_confusion_matrix,roc_auc_score,recall_score\nimport warnings\nwarnings.simplefilter('ignore')\n\nscaler = torch.cuda.amp.GradScaler() # GPUでの高速化。\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cpuがgpuかを自動判断\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.791619Z","iopub.execute_input":"2021-07-20T07:51:37.792124Z","iopub.status.idle":"2021-07-20T07:51:37.853394Z","shell.execute_reply.started":"2021-07-20T07:51:37.792090Z","shell.execute_reply":"2021-07-20T07:51:37.852661Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm._tqdm_notebook import tqdm_notebook as tq\ntq.pandas()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.854614Z","iopub.execute_input":"2021-07-20T07:51:37.854960Z","iopub.status.idle":"2021-07-20T07:51:37.860459Z","shell.execute_reply.started":"2021-07-20T07:51:37.854925Z","shell.execute_reply":"2021-07-20T07:51:37.859606Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nSEED = 508\n\ndef random_seed(SEED):\n    \n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n\nrandom_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.863731Z","iopub.execute_input":"2021-07-20T07:51:37.864054Z","iopub.status.idle":"2021-07-20T07:51:37.872399Z","shell.execute_reply.started":"2021-07-20T07:51:37.864029Z","shell.execute_reply":"2021-07-20T07:51:37.871506Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = '../input/jigsaw-toxic-comment-classification-challenge'\nunzip = zipfile.ZipFile('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\nunzip.extractall()\nunzip = zipfile.ZipFile('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\nunzip.extractall()\nunzip = zipfile.ZipFile('../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip')\nunzip.extractall()\nunzip = zipfile.ZipFile('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip')\nunzip.extractall()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:37.874570Z","iopub.execute_input":"2021-07-20T07:51:37.875041Z","iopub.status.idle":"2021-07-20T07:51:40.400075Z","shell.execute_reply.started":"2021-07-20T07:51:37.875005Z","shell.execute_reply":"2021-07-20T07:51:40.399233Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"./train.csv\")\ntest = pd.read_csv(\"./test.csv\")\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:40.401277Z","iopub.execute_input":"2021-07-20T07:51:40.401612Z","iopub.status.idle":"2021-07-20T07:51:41.949965Z","shell.execute_reply.started":"2021-07-20T07:51:40.401578Z","shell.execute_reply":"2021-07-20T07:51:41.948795Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['comment_text'] = train['comment_text'].progress_apply(lambda x: x.replace(\"\\n\",\" \"))\ntest['comment_text'] = test['comment_text'].progress_apply(lambda x: x.replace(\"\\n\",\" \"))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:41.951327Z","iopub.execute_input":"2021-07-20T07:51:41.951690Z","iopub.status.idle":"2021-07-20T07:51:42.782877Z","shell.execute_reply.started":"2021-07-20T07:51:41.951655Z","shell.execute_reply":"2021-07-20T07:51:42.781882Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/159571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f7d055da3d414fa69882373d07b429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/153164 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1285abc26b46a0bd8a822312a36067"}},"metadata":{}}]},{"cell_type":"code","source":"train['comment_text'] = train['comment_text'].fillna(\" \")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:42.785687Z","iopub.execute_input":"2021-07-20T07:51:42.786075Z","iopub.status.idle":"2021-07-20T07:51:42.821119Z","shell.execute_reply.started":"2021-07-20T07:51:42.786037Z","shell.execute_reply":"2021-07-20T07:51:42.820364Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\ntest['comment_text'] = test['comment_text'].fillna(\" \")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:42.822393Z","iopub.execute_input":"2021-07-20T07:51:42.822885Z","iopub.status.idle":"2021-07-20T07:51:42.854820Z","shell.execute_reply.started":"2021-07-20T07:51:42.822849Z","shell.execute_reply":"2021-07-20T07:51:42.854084Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n  \n    text = unidecode.unidecode(text)\n    text = contractions.fix(text)\n    exclist = string.punctuation \n    table_ = str.maketrans('', '', exclist)\n    text = text.translate(table_)\n    text = text.replace(\"'\",\"\")\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:42.856020Z","iopub.execute_input":"2021-07-20T07:51:42.856498Z","iopub.status.idle":"2021-07-20T07:51:42.861857Z","shell.execute_reply.started":"2021-07-20T07:51:42.856460Z","shell.execute_reply":"2021-07-20T07:51:42.860741Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain['comment_text'] = train['comment_text'].progress_apply(clean_text)\ntest['comment_text'] = test[\"comment_text\"].progress_apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:51:42.863266Z","iopub.execute_input":"2021-07-20T07:51:42.863743Z","iopub.status.idle":"2021-07-20T07:52:07.961043Z","shell.execute_reply.started":"2021-07-20T07:51:42.863709Z","shell.execute_reply":"2021-07-20T07:52:07.959914Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/159571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e64961cbea44475bffe22b5fc5c938f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/153164 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a32e9b640ec4d0983728a79790e99a4"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 24.9 s, sys: 183 ms, total: 25.1 s\nWall time: 25.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:07.962978Z","iopub.execute_input":"2021-07-20T07:52:07.963393Z","iopub.status.idle":"2021-07-20T07:52:07.981507Z","shell.execute_reply.started":"2021-07-20T07:52:07.963351Z","shell.execute_reply":"2021-07-20T07:52:07.980782Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n1  000103f0d9cfb60f  Daww He matches this background colour I am se...      0   \n2  000113f07ec002fd  Hey man I am really not trying to edit war it ...      0   \n3  0001b41b1c6bb37e   More I cannot make any real suggestions on im...      0   \n4  0001d958c54c6e35  You sir are my hero Any chance you remember wh...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation Why the edits made under my userna...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>Daww He matches this background colour I am se...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man I am really not trying to edit war it ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>More I cannot make any real suggestions on im...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You sir are my hero Any chance you remember wh...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train['comment_text'] = train['comment_text'].progress_apply(lambda x: x[:510])\ntest['comment_text'] = test['comment_text'].progress_apply(lambda x: x[:450])","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:07.982612Z","iopub.execute_input":"2021-07-20T07:52:07.982986Z","iopub.status.idle":"2021-07-20T07:52:09.193334Z","shell.execute_reply.started":"2021-07-20T07:52:07.982950Z","shell.execute_reply":"2021-07-20T07:52:09.190602Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/159571 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37a75c04b62747e6991668156fed2927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/153164 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"285319efebab46e4aabd6cd74fbeb7ae"}},"metadata":{}}]},{"cell_type":"code","source":"max_len = 500","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:09.195360Z","iopub.execute_input":"2021-07-20T07:52:09.197257Z","iopub.status.idle":"2021-07-20T07:52:09.216906Z","shell.execute_reply.started":"2021-07-20T07:52:09.197212Z","shell.execute_reply":"2021-07-20T07:52:09.215704Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:55:43.059436Z","iopub.execute_input":"2021-07-20T07:55:43.059760Z","iopub.status.idle":"2021-07-20T07:55:47.046358Z","shell.execute_reply.started":"2021-07-20T07:55:43.059729Z","shell.execute_reply":"2021-07-20T07:55:47.045439Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class BERTDataSet(Dataset):\n    \n    def __init__(self, sentences, targets):\n        \n        self.sentences = sentences\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        \n        bert_sens = tokenizer.encode_plus(\n                            sentence,\n                            add_special_tokens = True,\n                            max_length = 300,\n                            pad_to_max_length = True,\n                            truncation=True,\n                            return_attention_mask =True)\n        \n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n#         token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n        \n        target = torch.tensor(self.targets.iloc[idx].values, dtype=torch.float)\n        \n        return {\n            \n            'ids':ids,\n            'mask':mask,\n#             'token_type_ids':token_type_ids,\n            'targets': target\n        }\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:13.916481Z","iopub.execute_input":"2021-07-20T07:52:13.916823Z","iopub.status.idle":"2021-07-20T07:52:13.924633Z","shell.execute_reply.started":"2021-07-20T07:52:13.916786Z","shell.execute_reply":"2021-07-20T07:52:13.923376Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:13.926034Z","iopub.execute_input":"2021-07-20T07:52:13.926629Z","iopub.status.idle":"2021-07-20T07:52:14.148533Z","shell.execute_reply.started":"2021-07-20T07:52:13.926582Z","shell.execute_reply":"2021-07-20T07:52:14.147718Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"134"},"metadata":{}}]},{"cell_type":"code","source":"# pos_weight = torch.tensor([0.904,0.9899,0.947,0.997,0.950,0.991]).to(device)\ndef loss_fn(output,target):\n    return nn.BCEWithLogitsLoss()(output,target)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:52:14.151138Z","iopub.execute_input":"2021-07-20T07:52:14.151391Z","iopub.status.idle":"2021-07-20T07:52:14.157442Z","shell.execute_reply.started":"2021-07-20T07:52:14.151367Z","shell.execute_reply":"2021-07-20T07:52:14.156548Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def training(\n    dataloader,\n    model,\n    optimizer,\n    scheduler\n):\n    model.train()\n    torch.backends.cudnn.benchmark = True\n    \n    allpreds = []\n    alltargets = []\n    \n    for a in tqdm_notebook(train_dataloader):\n\n        losses = []\n\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n\n            ids = a[\"ids\"].to(device,non_blocking=True)\n            mask = a[\"mask\"].to(device,non_blocking=True)\n#             tokentype = a[\"token_type_ids\"].to(device,non_blocking=True)\n            logits = model(ids, mask)\n            targets = a[\"targets\"].to(device,non_blocking=True)\n            loss = loss_fn(logits, targets)\n\n            # For scoring\n            losses.append(loss.item())\n            allpreds.append(logits.detach().cpu().numpy())\n            alltargets.append(targets.detach().squeeze(-1).cpu().numpy())\n\n        scaler.scale(loss).backward() # backwards of loss\n        scaler.step(optimizer) # Update optimizer\n        scaler.update() # scaler update\n\n        scheduler.step() # Update learning rate schedule\n\n        # Combine dataloader minutes\n\n    allpreds = np.concatenate(allpreds)\n    alltargets = np.concatenate(alltargets).astype(int)\n\n    # I don't use loss, but I collect it\n\n    losses = np.mean(losses)\n    \n    allpreds = (allpreds >0.5).astype(int)\n    alltargets = (alltargets > 0.5).astype(int)\n    \n    try:\n        print(f\"Confusion matrix : \\n{multilabel_confusion_matrix(alltargets,allpreds)}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n\n    try:\n        print(f\"recall score: \\n{recall_score(alltargets,allpreds,average='macro')}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n\n    try:\n        print(f\"roc_auc score: \\n{roc_auc_score(alltargets,allpreds,average='macro')}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n        # Score with rmse\n        # Score with rmse\n    train_bce_loss = roc_auc_score(alltargets,allpreds,average=\"macro\")\n\n    return losses,train_bce_loss\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:24:42.545819Z","iopub.execute_input":"2021-07-16T06:24:42.546156Z","iopub.status.idle":"2021-07-16T06:24:42.559842Z","shell.execute_reply.started":"2021-07-16T06:24:42.546127Z","shell.execute_reply":"2021-07-16T06:24:42.55866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation(\n    dataloader,\n    model,\n):\n    model.eval()\n    \n    allpreds = []\n    alltargets = []\n    \n    for a in tqdm_notebook(valid_dataloader):\n        \n        losses = []\n        \n        with torch.no_grad():\n            \n            ids = a[\"ids\"].to(device, non_blocking=True)\n            mask = a[\"mask\"].to(device, non_blocking=True)\n#             tokentype = a[\"token_type_ids\"].to(device, non_blocking=True)\n            \n            logits = model(ids, mask)\n            \n            targets = a[\"targets\"].to(device, non_blocking=True)\n            loss = loss_fn(logits, targets)\n\n            # For scoring\n            losses.append(loss.item())\n            allpreds.append(logits.detach().cpu().numpy())\n            alltargets.append(targets.detach().squeeze(-1).cpu().numpy())\n\n    allpreds = np.concatenate(allpreds)\n    alltargets = np.concatenate(alltargets)\n\n    # I don't use loss, but I collect it\n\n    losses = np.mean(losses)\n    \n#     alltargets = [int(a) for a in alltargets]\n    allpreds = (allpreds >0.5).astype(int)\n    alltargets = (alltargets > 0.5).astype(int)\n    \n    try:\n        print(f\"Confusion matrix : \\n{multilabel_confusion_matrix(alltargets,allpreds)}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n        \n    try:\n        print(f\"recall score: \\n{recall_score(alltargets,allpreds,average='macro')}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n    \n    try:\n        print(f\"roc_auc score: \\n{roc_auc_score(alltargets,allpreds,average='macro')}\")\n    except TypeError as err:\n        print(\"Type error: {0}\".format(err))\n    except ValueError as err:\n        print(\"Type error: {0}\".format(err))\n    # Score with rmse\n    valid_bce_loss = roc_auc_score(alltargets,allpreds,average=\"macro\")\n\n    return allpreds, losses, valid_bce_loss\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:24:43.2445Z","iopub.execute_input":"2021-07-16T06:24:43.244825Z","iopub.status.idle":"2021-07-16T06:24:43.262472Z","shell.execute_reply.started":"2021-07-16T06:24:43.244795Z","shell.execute_reply":"2021-07-16T06:24:43.260372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()\n\ndef loss_fn(output,target):\n    return nn.BCEWithLogitsLoss()(output,target)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:24:44.596157Z","iopub.execute_input":"2021-07-16T06:24:44.59654Z","iopub.status.idle":"2021-07-16T06:24:44.780874Z","shell.execute_reply.started":"2021-07-16T06:24:44.596509Z","shell.execute_reply":"2021-07-16T06:24:44.779582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initializing the data\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nvalid_batch =64\ntrain_batch=32\nepochs = 10\nLR=5e-6\n\ntrain = train.sort_values(\"toxic\").reset_index(drop=True)\ntrain[\"kfold\"] = train.index % 5\n\np_train = train[train[\"kfold\"]!=1].reset_index(drop=True)\np_valid = train[train[\"kfold\"]==1].reset_index(drop=True)\n\ntrain_dataset = BERTDataSet(p_train[\"comment_text\"], p_train[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]])\nvalid_dataset = BERTDataSet(p_valid[\"comment_text\"], p_valid[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]])\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True,num_workers=4,pin_memory=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=valid_batch, shuffle=False, num_workers=4,pin_memory=True)\n\nmodel = transformers.BertForSequenceClassification.from_pretrained(\"./bert-base-uncased\",num_labels=6)\nclear_output()\n\nmodel.to(device)\nLR=5e-6\noptimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n\ntrain_steps = int(len(p_train)/train_batch*epochs)\n\nnum_steps = int(train_steps*0.1)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:54:52.840175Z","iopub.execute_input":"2021-07-20T07:54:52.840557Z","iopub.status.idle":"2021-07-20T07:55:22.555812Z","shell.execute_reply.started":"2021-07-20T07:54:52.840525Z","shell.execute_reply":"2021-07-20T07:55:22.554917Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainlosses = []\nvallosses = []\nbestscore = None\n\ntrainscores = []\nvalidscores = []\n\nfor epoch in tqdm_notebook(range(epochs)):\n    \n    print(\"---------------------\" + str(epoch) + \"start-------------------\")\n    \n    trainloss,trainscore = training(train_dataloader, model, optimizer, scheduler)\n    \n    trainlosses.append(trainloss)\n    trainscores.append(trainscore)\n    \n    print(\"traiscore is \" + str(trainscores))\n    print(\"trainloss is \" + str(trainloss))\n    \n    preds, validloss, valscore = validation(valid_dataloader, model)\n    \n    vallosses.append(validloss)\n    validscores.append(valscore)\n    \n    print(\"validscore is \" + str(valscore))\n    print(\"validloss is \" + str(vallosses))\n    \n    if bestscore is None:\n        bestscore = valscore\n        \n        print(\"Save first model\")\n        \n        state = {\n                        'state_dict' : model.state_dict(),\n                        'optimizer_dict' : optimizer.state_dict(),\n                        'bestscore': bestscore\n                    }\n        \n        torch.save(state, \"model_bce.pth\")\n        \n    elif bestscore < valscore:\n        bestscore = valscore\n        \n        print(\"found better point\")\n        \n        state = {\n                        'state_dict' : model.state_dict(),\n                        'optimizer_dict' : optimizer.state_dict(),\n                        'bestscore': bestscore\n                    }\n        \n        torch.save(state,\"model_bce.pth\")\n        \n    else:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:24:48.332302Z","iopub.execute_input":"2021-07-16T06:24:48.332651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class BERTinfDataSet(Dataset):\n    \n    def __init__(self,sentences):\n        \n        self.sentences = sentences\n       \n        \n    def __len__(self):\n        \n        return len(self.sentences)\n    \n    def __getitem__(self,idx):\n        \n        sentence = self.sentences[idx]\n        \n        \n        bert_sens = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True, # [CLS],[SEP]\n                                max_length = 314,\n                                pad_to_max_length = True, # add padding to blank\n                                truncation=True)\n\n        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n     \n        \n    \n        \n        return {\n                'ids': ids,\n                'mask': mask,\n                'token_type_ids': token_type_ids,\n                \n            }","metadata":{"execution":{"iopub.status.busy":"2021-07-20T07:56:54.214683Z","iopub.execute_input":"2021-07-20T07:56:54.215108Z","iopub.status.idle":"2021-07-20T07:56:54.222088Z","shell.execute_reply.started":"2021-07-20T07:56:54.215074Z","shell.execute_reply":"2021-07-20T07:56:54.221007Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_dataset = BERTinfDataSet(test[\"comment_text\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T20:30:18.805359Z","iopub.execute_input":"2021-07-14T20:30:18.807811Z","iopub.status.idle":"2021-07-14T20:30:18.818711Z","shell.execute_reply.started":"2021-07-14T20:30:18.807766Z","shell.execute_reply":"2021-07-14T20:30:18.817565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch = 32","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:38:31.636409Z","iopub.execute_input":"2021-07-15T11:38:31.636834Z","iopub.status.idle":"2021-07-15T11:38:32.060431Z","shell.execute_reply.started":"2021-07-15T11:38:31.636795Z","shell.execute_reply":"2021-07-15T11:38:32.057801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=4,pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained('./bert-base-uncased',num_labels=6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\npthes","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:59:19.963322Z","iopub.status.idle":"2021-07-14T15:59:19.963903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predicting(\n    test_dataloader,\n    model,\n    pthes\n    \n):\n\n    allpreds = []\n    \n    for pth in pthes:\n        \n        state = torch.load(pth)\n        \n        model.load_state_dict(state[\"state_dict\"])\n        model.to(device)\n        model.eval()\n    \n    \n        preds = []\n        allvalloss=0\n\n        with torch.no_grad():\n\n\n            for a in tqdm_notebook(test_dataloader):\n\n\n\n                ids = a[\"ids\"].to(device)\n                mask = a[\"mask\"].to(device)\n                tokentype = a[\"token_type_ids\"].to(device)\n\n               # output = model(ids,mask,tokentype)\n                output = model(ids,mask)\n\n                output = output[\"logits\"]\n\n\n                preds.append(output.cpu().numpy())\n\n            preds = np.concatenate(preds)\n            \n            allpreds.append(preds)\n\n    return allpreds\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:59:19.965269Z","iopub.status.idle":"2021-07-14T15:59:19.96593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence = train['comment_text'][0]\n\ntokenized_sequence = tokenizer.tokenize(sequence)\n\ntokenized_sequence","metadata":{"execution":{"iopub.status.busy":"2021-07-14T15:59:19.967324Z","iopub.status.idle":"2021-07-14T15:59:19.967905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allpreds = predicting(test_dataloader,model,pthes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction= np.concatenate(allpreds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"findf = pd.DataFrame(prediction)\nsubm = pd.read_csv(\"sample_submission.csv\")\nsubm[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]] = findf","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}